# Kafka

Kafka属于分布式的消息引擎系统，它的主要功能是提供一套完备的消息发布与订阅解决方案。

### Kafka工作流程

**主题（Topic）**：发布订阅的对象，承载消息的逻辑容器，主要用来区分具体的业务。

**生产者（Product）**：向主题发送消息的客户端应用程序。

**消费者（Consumer）**：订阅主题消息的客户端应用程序。

**Broker**：构成Kafka服务器端的服务进程，一个Kafka集群由多个Broker组成，Broker负责接收和处理客户端发送过来的请求，以及对消息进行持久化。可将Broker分散运行在不同的机器上，以实现Kafka的高可用。

**Replica**：副本。实现高可用的另一个手段就是备份机制。备份就是将相同的数据拷贝到多台机器上，而这些相同的数据拷贝在Kafka中被称为副本。副本的数量可配置，分为两类：**领导者副本和追随者副本**。前者对外提供服务，而后者只是被动地追随领导者副本而已，不能与外界进行交互。

副本的工作机制：生产者总是向领导者副本写消息，消费者总是向领导者副本读消息。而追随者副本，它只是向领导者副本发送请求，请求领导者副本把最新的消息发给它，这样它就能保持与领导者的同步。

**分区（Partitioning）**：Kafka中的分区机制指的是将每个主题划分成多个分区，每个分区是一组有序的消息日志。生产者生产的每条消息只会被发送到一个分区中。如果向一个双分区的主题发送一条消息，这条消息要么在分区0中，要么在分区1中。分区机制保证了Kafka的伸缩性。

分区与副本的联系：实际上，副本是在分区这个层级定义下的。每个分区下可以配置若干个副本，其中只能有1个领导者副本和N-1个追随者副本。生产者向分区写入消息，每条消息在分区中的位置信息由一个叫位移（Offset）的数据来表示。

#### Kafka的三层架构

- 第一层是主题层，每个主题可以配置N个分区，而每个分区又可以配置N个副本。
- 第二层是分区层，每个分区的N个副本中只能有一个充当领导者的角色，其他副本是追随者副本，只提供数据冗余作用。
- 第三层是消息层，分区中包含若干条消息，每条消息的位移从0开始，一次递增。
- 最后，客户端程序只能与分区领导者副本进行交互。

#### 持久化数据

Kafka在Broker中持久化数据。Kafka使用消息日志（Log）来保存数据，一个日志就是磁盘上一个只能追加写消息的物理文件。因为只能追加写入，故避免了缓慢的随机I/O写操作，改为性能较好的顺序I/O写操作，这也是实现Kafka高吞吐量的一个重要手段。不过如果不停地向一个日志写入消息，最终也会耗尽磁盘空间，所以，Kafka会定时期地删除消息以回收磁盘空间。

**Kafka如何删除消息**

简单来说，就是通过日志段（Log Segment）机制。在Kafka底层，一个日志又进一步细分成多个日志段，消息被追加写到最新的日志段，当一个新的日志段写满后，Kafka会自动切分出一个新的日志段，并将老的日志段封存起来，再通过定时任务定期地检查老的日志段是否能够被删除，从而实现回收磁盘空间的目的。

#### 消费者模型

消息模型有两种：

- 点对点模型：同一条消息只能被一个消费者消费
- 发布订阅模型：生产发布完消息后，由多个消费者订阅

Kafka中实现点对点模型的方式是使用**消费者组**。所谓消费者组，指的是将多个消费者实例共同组成一个组来消费一组主题。这组主题中的每个消息只能被消费者组中的一个实例消费。引入消费者组的目的主要是为了提升消费者端的吞吐量。多个消费者实例同时消费，加速整个消费端的吞吐量（TPS）。消费者组中的所有消费者实例不仅能共同消费消息，还能彼此协作。假设组内某个消费者实例挂掉了，Kafka能够自动检测到，然后把这个实例之前负责的分区转移给其他的消费者。这个过程就是Kafka的**重平衡**（Rebalance）。

消费者消费消息的过程中需要有个字段来记录它当前消费的位置，这个字段就是消费者位移。注意与分区位移的区别，分区位移指的是消息写入分区的位置，它的位值是固定的。而消费者位移是随时变化的，毕竟它是消息者消费消息的指示器。每个消费者有自己的消费者位移。

思考：为什么Kafka不像MySQL那样允许追随者副本对外提供读服务？

1. 主从读写分离的适用场景应该是那种读操作很多而写操作相对不频繁的负载类型，通过添加很多的follower横向扩展，提升读操作性能。而Kafka，它的主要场景还是在消息引擎而不是以数据存储的方式对外提供读服务，通常涉及频繁的生产消息和消费消息，不属于读多写少的场景，因此读写分离方案在这个场景下并不合适。
2. Kafka副本机制使用的是异步消息来拉取，因此存在leader和follower之间的不一致性。如果要采用读写分离，必然要处理副本的一致性问题，增加复杂性。

### Kafka参数配置

### 生产者消息分区机制原理

Kafka使用分区的作用就是提供负载均衡的能力，实现系统的高伸缩性。不同的分区能够被放置在不同的节点机器上，而数据的读写操作也都是针对分区这个粒度来进行的，这样每个节点的机器都能独立地执行各自分区的读写请求处理。

利用分区也可以实现业务级别的需求，比如实现业务级别的消息顺序的问题。

#### 分区策略

分区策略就是决定生产者将消息发送到哪个分区的算法。Kafka为我们提供了默认的分区策略，同时也支持你自定义分区策略。

**自定义分区策略**

编写生产者程序时，编写一个具体的类实现`org.apache.kafka.clients.producer.Partitioner`接口。这个接口只定义了两个方法：partition()和close()，通常你只需要实现最重要的partition方法。

```java
int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);
```

partition的方法签名：topic、key、keyBytes、value、valueBytes都属于消息数据，cluster则是集群消息（比如当前kafka集群共有多少个主题、多少Broker等）。你需要充分利用好这些信息，计算好你需要发送的分区。所以，你只要实现类定义好了partiton方法，同时设置partition.class参数为你自己实现类的Full Qualified Name，那么生产者程序就会按照你的代码逻辑对消息进行分区。 

### 生产者压缩算法







